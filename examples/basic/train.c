/* This is a really, really simple example on how to train a neural network with Axon.
 * In this example, the network code was generated from the equation: y = mx + b
 * The training data is generated procedurally.
 * */

/* This header is generated by the "compiler". The "compiler" is a program that takes
 * a description of a neural network and generates code to run and train it with.
 * The compiler for this example is in the same directory as this file, called "compiler.cpp".
 * */
#include "basic.h"

#include <stdio.h>

/* In this example, this is the line equation that we're trying to get our network to fit.
 * */
static inline float
func(float x)
{
  return -4.29F * x + 1.5F;
}

int
main()
{
  const float lr = 0.001F;
  const float momentum = 0.9F;
  const int epochs = 100;
  const int train_samples = 8;
  const int val_samples = 2;

  float parameters[AXON_PARAMETERS];
  float grad_input[AXON_GRAD_INPUTS];
  float eval_input[AXON_EVAL_INPUTS];
  float eval_output[AXON_EVAL_OUTPUTS];

  axon_rng_z rng;
  axon_rng_init(&rng, 0);
  axon_rng_float_array(&rng, parameters, AXON_PARAMETERS, 2.0F, -1.0F);

  axon_opt_z opt;

  axon_opt_init(&opt, 0);

  for (int i = 0; i < epochs; i++) {

    for (int j = 0; j < train_samples; j++) {

      const float x = axon_rng_float(&rng) * 10.0F - 5.0F;

      grad_input[0] = x;       /* the input */
      grad_input[1] = func(x); /* the expected output */

      axon_grad(parameters, grad_input, opt.gradient);

      axon_opt_step(&opt, lr, momentum, parameters);
    }

    float val_loss = 0.0F;

    for (int j = 0; j < val_samples; j++) {

      const float x = axon_rng_float(&rng) * 10.0F - 5.0F;

      eval_input[0] = x;
      axon_eval(parameters, eval_input, eval_output);
      const float y = eval_output[0];
      const float y_target = func(x);
      const float y_delta = y_target - y;
      const float loss = y_delta * y_delta;

      val_loss += loss;
    }
    val_loss *= (1.0F / ((float)val_samples));

    printf("epoch[%d]: %f\n", i, val_loss);
  }

  return 0;
}
